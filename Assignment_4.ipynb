{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YZ_oVLxvuTEb",
        "DbkzsQ-DwYaZ",
        "c_O5nM76yWe8",
        "rPC7-yucFmhz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ_oVLxvuTEb"
      },
      "source": [
        "#Download & Unzip Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XEC1sXmEMEg"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/DL/ADE20K_1.zip ./\n",
        "! cp /content/drive/MyDrive/DL/ADE20K_2.zip ./\n",
        "! cp /content/drive/MyDrive/DL/VOC2007.zip ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ADE20K\n",
        "!mkdir VOC2007\n",
        "!unzip /content/ADE20K_1.zip -d ./ADE20K\n",
        "!unzip /content/ADE20K_2.zip -d ./ADE20K\n",
        "!unzip /content/VOC2007.zip -d ./VOC2007"
      ],
      "metadata": {
        "id": "yRiRLCPq1cJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /content/ADE20K/ADE20K/ADE20K_DL_course/imgs/ADE_val_00001280\\(1\\).jpg\n",
        "! rm /content/ADE20K/ADE20K/ADE20K_DL_course/imgs/ADE_val_00001281\\(1\\).jpg\n",
        "! rm /content/ADE20K/ADE20K/ADE20K_DL_course/imgs/ADE_val_00001282\\(1\\).jpg\n",
        "! rm /content/ADE20K/ADE20K/ADE20K_DL_course/imgs/ADE_val_00001283\\(1\\).jpg\n",
        "! rm /content/ADE20K/ADE20K/ADE20K_DL_course/imgs/ADE_val_00001285\\(1\\).jpg"
      ],
      "metadata": {
        "id": "oeEOcMRyIjq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbkzsQ-DwYaZ"
      },
      "source": [
        "# Starter Code ADE20K\n",
        "This notebook contains a tutorial on how to explore data in ADE20K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import"
      ],
      "metadata": {
        "id": "c_O5nM76yWe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib._color_data as mcd\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "_NUMERALS = '0123456789abcdefABCDEF'\n",
        "_HEXDEC = {v: int(v, 16) for v in (x+y for x in _NUMERALS for y in _NUMERALS)}\n",
        "LOWERCASE, UPPERCASE = 'x', 'X'\n",
        "def rgb(triplet):\n",
        "    return _HEXDEC[triplet[0:2]], _HEXDEC[triplet[2:4]], _HEXDEC[triplet[4:6]]\n",
        "\n",
        "def loadAde20K(file):\n",
        "    fileseg = \"/content/ADE20K/ADE20K/ADE20K_DL_course/masks/\"+file.replace('.jpg', '_seg.png').split(\"/\")[-1];\n",
        "    with Image.open(fileseg) as io:\n",
        "        seg = np.array(io);\n",
        "\n",
        "    # Obtain the segmentation mask, bult from the RGB channels of the _seg file\n",
        "    R = seg[:,:,0];\n",
        "    G = seg[:,:,1];\n",
        "    B = seg[:,:,2];\n",
        "    ObjectClassMasks = (R/10).astype(np.int32)*256+(G.astype(np.int32));\n",
        "\n",
        "\n",
        "    # Obtain the instance mask from the blue channel of the _seg file\n",
        "    Minstances_hat = np.unique(B, return_inverse=True)[1]\n",
        "    Minstances_hat = np.reshape(Minstances_hat, B.shape)\n",
        "    ObjectInstanceMasks = Minstances_hat\n",
        "\n",
        "\n",
        "    level = 0\n",
        "    PartsClassMasks = [];\n",
        "    PartsInstanceMasks = [];\n",
        "    while True:\n",
        "        level = level+1;\n",
        "        file_parts = file.replace('.jpg', f'_parts_{level:03}.png');\n",
        "        if os.path.isfile(file_parts):\n",
        "            with Image.open(file_parts) as io:\n",
        "                partsseg = np.array(io);\n",
        "            R = partsseg[:,:,0];\n",
        "            G = partsseg[:,:,1];\n",
        "            B = partsseg[:,:,2];\n",
        "            PartsClassMasks.append((np.int32(R)/10)*256+np.int32(G));\n",
        "            PartsInstanceMasks = PartsClassMasks\n",
        "            # TODO:  correct partinstancemasks\n",
        "\n",
        "\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    objects = {}\n",
        "    parts = {}\n",
        "\n",
        "    attr_file_name = \"/content/ADE20K/ADE20K/ADE20K_DL_course/jsons/\" + file.replace('.jpg', '.json').split(\"/\")[-1];\n",
        "    if os.path.isfile(attr_file_name):\n",
        "        with open(attr_file_name, 'r') as f:\n",
        "            input_info = json.load(f)\n",
        "\n",
        "        contents = input_info['annotation']['object']\n",
        "        instance = np.array([int(x['id']) for x in contents])\n",
        "        names = [x['raw_name'] for x in contents]\n",
        "        corrected_raw_name =  [x['name'] for x in contents]\n",
        "        partlevel = np.array([int(x['parts']['part_level']) for x in contents])\n",
        "        ispart = np.array([p>0 for p in partlevel])\n",
        "        iscrop = np.array([int(x['crop']) for x in contents])\n",
        "        listattributes = [x['attributes'] for x in contents]\n",
        "        polygon = [x['polygon'] for x in contents]\n",
        "        for p in polygon:\n",
        "            p['x'] = np.array(p['x'])\n",
        "            p['y'] = np.array(p['y'])\n",
        "\n",
        "        objects['instancendx'] = instance[ispart == 0]\n",
        "        objects['class'] = [names[x] for x in list(np.where(ispart == 0)[0])]\n",
        "        objects['corrected_raw_name'] = [corrected_raw_name[x] for x in list(np.where(ispart == 0)[0])]\n",
        "        objects['iscrop'] = iscrop[ispart == 0]\n",
        "        objects['listattributes'] = [listattributes[x] for x in list(np.where(ispart == 0)[0])]\n",
        "        objects['polygon'] = [polygon[x] for x in list(np.where(ispart == 0)[0])]\n",
        "\n",
        "\n",
        "        parts['instancendx'] = instance[ispart == 1]\n",
        "        parts['class'] = [names[x] for x in list(np.where(ispart == 1)[0])]\n",
        "        parts['corrected_raw_name'] = [corrected_raw_name[x] for x in list(np.where(ispart == 1)[0])]\n",
        "        parts['iscrop'] = iscrop[ispart == 1]\n",
        "        parts['listattributes'] = [listattributes[x] for x in list(np.where(ispart == 1)[0])]\n",
        "        parts['polygon'] = [polygon[x] for x in list(np.where(ispart == 1)[0])]\n",
        "\n",
        "    return {'img_name': file, 'segm_name': fileseg,\n",
        "            'class_mask': ObjectClassMasks, 'instance_mask': ObjectInstanceMasks,\n",
        "            'partclass_mask': PartsClassMasks, 'part_instance_mask': PartsInstanceMasks,\n",
        "            'objects': objects, 'parts': parts}\n",
        "\n",
        "def plot_polygon(img_name, info, show_obj=True, show_parts=False):\n",
        "    colors = mcd.CSS4_COLORS\n",
        "    color_keys = list(colors.keys())\n",
        "    all_objects = []\n",
        "    all_poly = []\n",
        "    if show_obj:\n",
        "        all_objects += info['objects']['class']\n",
        "        all_poly += info['objects']['polygon']\n",
        "    if show_parts:\n",
        "        all_objects += info['parts']['class']\n",
        "        all_poly += info['objects']['polygon']\n",
        "\n",
        "    img = cv2.imread(img_name)\n",
        "    thickness = 5\n",
        "    for it, (obj, poly) in enumerate(zip(all_objects, all_poly)):\n",
        "        curr_color = colors[color_keys[it % len(color_keys)] ]\n",
        "        pts = np.concatenate([poly['x'][:, None], poly['y'][:, None]], 1)[None, :]\n",
        "        color = rgb(curr_color[1:])\n",
        "        img = cv2.polylines(img, pts, True, color, thickness)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "B5Yed_1nyPF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nynqlVWcwYac"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import IPython.display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3L1ZMG-wYad"
      },
      "source": [
        "## Dataset index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqHJeJoBwYad"
      },
      "outputs": [],
      "source": [
        "# Load index with global information about ADE20K\n",
        "DATASET_PATH = '/content/ADE20K/ADE20K/ADE20K_DL_course'\n",
        "index_file = 'index_ade20k.pkl'\n",
        "with open('{}/{}'.format(DATASET_PATH, index_file), 'rb') as f:\n",
        "    index_ade20k = pkl.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "objectIsPart = []\n",
        "for i in range(len(index_ade20k[\"objectIsPart\"])):\n",
        "  objectIsPart.append(index_ade20k[\"objectIsPart\"][i][25258:27258])\n",
        "objectIsPart = np.array(objectIsPart)"
      ],
      "metadata": {
        "id": "QvjJkL2i8pwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objectPresence = []\n",
        "for i in range(len(index_ade20k[\"objectPresence\"])):\n",
        "  objectPresence.append(index_ade20k[\"objectPresence\"][i][25258:27258])\n",
        "objectPresence = np.array(objectPresence)"
      ],
      "metadata": {
        "id": "2Br7GkHL-h3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = {}\n",
        "new[\"filename\"] = index_ade20k[\"filename\"][25258:27258]\n",
        "new[\"objectIsPart\"] = objectIsPart\n",
        "new[\"objectPresence\"] = objectPresence\n",
        "new[\"objectcounts\"] = index_ade20k[\"objectcounts\"]\n",
        "new[\"objectnames\"] = index_ade20k[\"objectnames\"]\n",
        "new[\"scene\"] = index_ade20k[\"scene\"][25258:27258]\n",
        "new[\"wordnet_found\"] = index_ade20k[\"wordnet_found\"]\n",
        "new[\"wordnet_level1\"] = index_ade20k[\"wordnet_level1\"]\n",
        "new[\"wordnet_synset\"] = index_ade20k[\"wordnet_synset\"]\n",
        "new[\"wordnet_hypernym\"] = index_ade20k[\"wordnet_hypernym\"]\n",
        "new[\"wordnet_gloss\"] = index_ade20k[\"wordnet_gloss\"]\n",
        "new[\"wordnet_frequency\"] = index_ade20k[\"wordnet_frequency\"]\n",
        "new[\"description\"] = index_ade20k[\"description\"]"
      ],
      "metadata": {
        "id": "QBMzR9122t1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new[\"filename\"][0])\n",
        "print(new[\"filename\"][1999])"
      ],
      "metadata": {
        "id": "rkk7Tw7-10_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "STPuseAnwYad"
      },
      "outputs": [],
      "source": [
        "# print(\"File loaded, description of the attributes:\")\n",
        "# print('--------------------------------------------')\n",
        "# for attribute_name, desc in new['description'].items():\n",
        "#     print('* {}: {}'.format(attribute_name, desc))\n",
        "# print('--------------------------------------------\\n')\n",
        "\n",
        "ADE = {}\n",
        "for i in range(2000):\n",
        "  ADE[i] = {}\n",
        "  nfiles = len(new['filename'])\n",
        "  ADE[i][\"file_name\"] = new['filename'][i]\n",
        "  ADE[i][\"num_obj\"] = new['objectPresence'][:, i].sum()\n",
        "  ADE[i][\"num_parts\"] = new['objectIsPart'][:, i].sum()\n",
        "  count_obj = new['objectPresence'][:, i].max()\n",
        "  obj_id = np.where(new['objectPresence'][:, i] == count_obj)[0][0]\n",
        "  obj_name = new['objectnames'][obj_id]\n",
        "  full_file_name = '{}/{}'.format(\"imgs\", new['filename'][i])\n",
        "  ADE[i][\"count_obj\"] = count_obj\n",
        "  ADE[i][\"obj_id\"] = obj_id\n",
        "  ADE[i][\"obj_name\"] = obj_name\n",
        "  ADE[i][\"full_file_name\"] = full_file_name\n",
        "\n",
        "print(\"The dataset has {} images\".format(nfiles))\n",
        "print(\"The image at index {} is {}\".format(i, ADE[i][\"file_name\"]))\n",
        "print(\"It is located at {}\".format(full_file_name))\n",
        "print(\"It happens in a {}\".format(new['scene'][i]))\n",
        "print(\"It has {} objects, of which {} are parts\".format(ADE[i][\"num_obj\"], ADE[i][\"num_parts\"]))\n",
        "print(\"The most common object is object {} ({}), which appears {} times\".format(obj_name, obj_id, count_obj))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJRoQA-4wYae"
      },
      "outputs": [],
      "source": [
        "root_path = DATASET_PATH\n",
        "\n",
        "# This function reads the image and mask files and generate instance and segmentation\n",
        "# masks\n",
        "\n",
        "i = 1999\n",
        "info = loadAde20K('{}/{}'.format(root_path, ADE[i][\"full_file_name\"]))\n",
        "img = cv2.imread(info['img_name'])[:,:,::-1]\n",
        "seg = cv2.imread(info['segm_name'])[:,:,::-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info[\"objects\"]"
      ],
      "metadata": {
        "id": "gFZlpPzjYrQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwjA1PWPwYaf"
      },
      "source": [
        "You can also inspect the attributes `info['objects']` and `info['parts']` for information about object names, attributes etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VOC 2007"
      ],
      "metadata": {
        "id": "rPC7-yucFmhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "root_train_imgs = \"/content/ADE20K/ADE20K/ADE20K_DL_course/imgs/\"\n",
        "root_train_mask = \"/content/ADE20K/ADE20K/ADE20K_DL_course/masks/\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "HbBy7haUydo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "class RoadDataset(Dataset):\n",
        "\n",
        "    def __init__(self, width, height, path_to_imgs, path_to_mask, transform = None):\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.path_to_img = path_to_imgs\n",
        "        self.path_to_mask= path_to_mask\n",
        "\n",
        "        self.train_imgs = os.listdir(path_to_imgs)\n",
        "        self.train_mask = os.listdir(path_to_mask)\n",
        "\n",
        "        self.length = len(self.train_imgs)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = cv.imread(self.path_to_img + self.train_imgs[index])\n",
        "        msk = cv.imread(self.path_to_mask + self.train_mask[index])\n",
        "\n",
        "        img_resize = cv.resize(img, (self.width, self.height), interpolation = cv.INTER_CUBIC)\n",
        "        msk_resize = cv.resize(msk, (self.width, self.height), interpolation = cv.INTER_NEAREST)\n",
        "\n",
        "        msk_transpose = msk_resize.transpose((2, 0, 1))\n",
        "        msk_one_channel = msk_transpose[0]\n",
        "\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_resize)\n",
        "\n",
        "        return (img_tensor, msk_one_channel)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "# This will normalize the image value\n",
        "trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Set DataLoader\n",
        "width = 256\n",
        "height = 256\n",
        "batch_size = 12\n",
        "\n",
        "Train_Dataset = RoadDataset(width, height, root_train_imgs, root_train_mask, trans)\n",
        "Train_Dataloader = DataLoader(Train_Dataset, batch_size = batch_size, shuffle = True, num_workers = 0)"
      ],
      "metadata": {
        "id": "e68k9jkAyayk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "RvFc34LMNwU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "backbone(ResNet50)"
      ],
      "metadata": {
        "id": "vL-YlvymDXW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "fc_initializer = tf.keras.initializers.glorot_normal\n",
        "conv2d_initializer = tf.keras.initializers.GlorotNormal\n",
        "\n",
        "# create weight variable\n",
        "def create_var(name, shape, initializer, trainable=True):\n",
        "    return tf.compat.v1.get_variable(name, shape=shape, dtype=tf.float32,\n",
        "                           initializer=initializer, trainable=trainable)\n",
        "\n",
        "# conv2d layer\n",
        "def conv2d(x, num_outputs, kernel_size, stride=1, scope=\"conv2d\"):\n",
        "    num_inputs = x.get_shape()[-1]\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        kernel = create_var(\"kernel\", [kernel_size, kernel_size,\n",
        "                                       num_inputs, num_outputs],\n",
        "                            conv2d_initializer())\n",
        "        return tf.nn.conv2d(x, kernel, strides=[1, stride, stride, 1],\n",
        "                            padding=\"SAME\")\n",
        "\n",
        "# fully connected layer\n",
        "def fc(x, num_outputs, scope=\"fc\"):\n",
        "    num_inputs = x.get_shape()[-1]\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        weight = create_var(\"weight\", [num_inputs, num_outputs],\n",
        "                            fc_initializer())\n",
        "        bias = create_var(\"bias\", [num_outputs,],\n",
        "                          tf.zeros_initializer())\n",
        "        return tf.compat.v1.nn.xw_plus_b(x, weight, bias)\n",
        "\n",
        "\n",
        "# batch norm layer\n",
        "def batch_norm(x, decay=0.999, epsilon=1e-03, is_training=True,\n",
        "               scope=\"scope\"):\n",
        "    x_shape = x.get_shape()\n",
        "    num_inputs = x_shape[-1]\n",
        "    reduce_dims = list(range(len(x_shape) - 1))\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        beta = create_var(\"beta\", [num_inputs,],\n",
        "                               initializer=tf.zeros_initializer())\n",
        "        gamma = create_var(\"gamma\", [num_inputs,],\n",
        "                                initializer=tf.ones_initializer())\n",
        "        # for inference\n",
        "        moving_mean = create_var(\"moving_mean\", [num_inputs,],\n",
        "                                 initializer=tf.zeros_initializer(),\n",
        "                                 trainable=False)\n",
        "        moving_variance = create_var(\"moving_variance\", [num_inputs],\n",
        "                                     initializer=tf.ones_initializer(),\n",
        "                                     trainable=False)\n",
        "    if is_training:\n",
        "        mean, variance = tf.nn.moments(x, axes=reduce_dims)\n",
        "        update_move_mean = moving_averages.assign_moving_average(moving_mean,\n",
        "                                                mean, decay=decay)\n",
        "        update_move_variance = moving_averages.assign_moving_average(moving_variance,\n",
        "                                                variance, decay=decay)\n",
        "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, update_move_mean)\n",
        "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, update_move_variance)\n",
        "    else:\n",
        "        mean, variance = moving_mean, moving_variance\n",
        "    return tf.nn.batch_normalization(x, mean, variance, beta, gamma, epsilon)\n",
        "\n",
        "\n",
        "# avg pool layer\n",
        "def avg_pool(x, pool_size, scope):\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        return tf.nn.avg_pool(x, [1, pool_size, pool_size, 1],\n",
        "                strides=[1, pool_size, pool_size, 1], padding=\"VALID\")\n",
        "\n",
        "# max pool layer\n",
        "def max_pool(x, pool_size, stride, scope):\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        return tf.nn.max_pool(x, [1, pool_size, pool_size, 1],\n",
        "                              [1, stride, stride, 1], padding=\"SAME\")\n",
        "\n",
        "class ResNet50(object):\n",
        "    def __init__(self, inputs, num_classes=1000, is_training=True,\n",
        "                 scope=\"resnet50\"):\n",
        "        self.inputs =inputs\n",
        "        self.is_training = is_training\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        with tf.compat.v1.variable_scope(scope):\n",
        "            # construct the model\n",
        "            net = conv2d(inputs, 64, 7, 2, scope=\"conv1\") # -> [batch, 112, 112, 64]\n",
        "            net = tf.nn.relu(batch_norm(net, is_training=self.is_training, scope=\"bn1\"))\n",
        "            net = max_pool(net, 3, 2, scope=\"maxpool1\")  # -> [batch, 56, 56, 64]\n",
        "            net = self._block(net, 256, 3, init_stride=1, is_training=self.is_training,\n",
        "                              scope=\"block2\")           # -> [batch, 56, 56, 256]\n",
        "            net = self._block(net, 512, 4, is_training=self.is_training, scope=\"block3\")\n",
        "                                                        # -> [batch, 28, 28, 512]\n",
        "            net = self._block(net, 1024, 6, is_training=self.is_training, scope=\"block4\")\n",
        "                                                        # -> [batch, 14, 14, 1024]\n",
        "            net = self._block(net, 2048, 3, is_training=self.is_training, scope=\"block5\")\n",
        "                                                        # -> [batch, 7, 7, 2048]\n",
        "            net = avg_pool(net, 7, scope=\"avgpool5\")    # -> [batch, 1, 1, 2048]\n",
        "            net = tf.squeeze(net, [1, 2], name=\"SpatialSqueeze\") # -> [batch, 2048]\n",
        "            self.logits = fc(net, self.num_classes, \"fc6\")       # -> [batch, num_classes]\n",
        "            self.predictions = tf.nn.softmax(self.logits)\n",
        "\n",
        "\n",
        "    def _block(self, x, n_out, n, init_stride=2, is_training=True, scope=\"block\"):\n",
        "        with tf.compat.v1.variable_scope(scope):\n",
        "            h_out = n_out // 4\n",
        "            out = self._bottleneck(x, h_out, n_out, stride=init_stride,\n",
        "                                   is_training=is_training, scope=\"bottlencek1\")\n",
        "            for i in range(1, n):\n",
        "                out = self._bottleneck(out, h_out, n_out, is_training=is_training,\n",
        "                                       scope=(\"bottlencek%s\" % (i + 1)))\n",
        "            return out\n",
        "\n",
        "    def _bottleneck(self, x, h_out, n_out, stride=None, is_training=True, scope=\"bottleneck\"):\n",
        "        \"\"\" A residual bottleneck unit\"\"\"\n",
        "        n_in = x.get_shape()[-1]\n",
        "        if stride is None:\n",
        "            stride = 1 if n_in == n_out else 2\n",
        "\n",
        "        with tf.compat.v1.variable_scope(scope):\n",
        "            h = conv2d(x, h_out, 1, stride=stride, scope=\"conv_1\")\n",
        "            h = batch_norm(h, is_training=is_training, scope=\"bn_1\")\n",
        "            h = tf.nn.relu(h)\n",
        "            h = conv2d(h, h_out, 3, stride=1, scope=\"conv_2\")\n",
        "            h = batch_norm(h, is_training=is_training, scope=\"bn_2\")\n",
        "            h = tf.nn.relu(h)\n",
        "            h = conv2d(h, n_out, 1, stride=1, scope=\"conv_3\")\n",
        "            h = batch_norm(h, is_training=is_training, scope=\"bn_3\")\n",
        "\n",
        "            if n_in != n_out:\n",
        "                shortcut = conv2d(x, n_out, 1, stride=stride, scope=\"conv_4\")\n",
        "                shortcut = batch_norm(shortcut, is_training=is_training, scope=\"bn_4\")\n",
        "            else:\n",
        "                shortcut = x\n",
        "            return tf.nn.relu(shortcut + h)\n",
        "\n",
        "\n",
        "#test\n",
        "if __name__ == \"__main__\":\n",
        "    x = tf.random.normal([32, 224, 224, 3])\n",
        "    resnet50 = ResNet50(x)\n",
        "    print(resnet50.logits)"
      ],
      "metadata": {
        "id": "SBNeqH7QQqiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bottleneck_Object_detection (YOLO)"
      ],
      "metadata": {
        "id": "io-87YxADV5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "######## basic layers #######\n",
        "\n",
        "def leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.1, name=\"leaky_relu\")\n",
        "\n",
        "# Conv2d\n",
        "def conv2d(x, filters, size, pad=0, stride=1, batch_normalize=1,\n",
        "           activation=leaky_relu, use_bias=False, name=\"conv2d\"):\n",
        "    if pad > 0:\n",
        "        x = tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]])\n",
        "    out = tf.keras.layers.Conv2D(filters, size, strides=stride, padding=\"VALID\",\n",
        "                           activation=None, use_bias=use_bias, name=name)(x)\n",
        "    if batch_normalize == 1:\n",
        "        out = tf.compat.v1.layers.batch_normalization(out, axis=-1, momentum=0.9,\n",
        "                                            training=False, name=name+\"_bn\")\n",
        "    if activation:\n",
        "        out = activation(out)\n",
        "    return out\n",
        "\n",
        "# maxpool2d\n",
        "def maxpool(x, size=2, stride=2, name=\"maxpool\"):\n",
        "    return tf.compat.v1.layers.max_pooling2d(x, size, stride)\n",
        "\n",
        "# reorg layer\n",
        "def reorg(x, stride):\n",
        "    return tf.compat.v1.extract_image_patches(x, [1, stride, stride, 1],\n",
        "                        [1, stride, stride, 1], [1,1,1,1], padding=\"VALID\")\n",
        "\n",
        "\n",
        "def darknet(images, n_last_channels=425):\n",
        "    \"\"\"Darknet19 for YOLOv2\"\"\"\n",
        "    net = conv2d(images, 32, 3, 1, name=\"conv1\")\n",
        "    net = maxpool(net, name=\"pool1\")\n",
        "    net = conv2d(net, 64, 3, 1, name=\"conv2\")\n",
        "    net = maxpool(net, name=\"pool2\")\n",
        "    net = conv2d(net, 128, 3, 1, name=\"conv3_1\")\n",
        "    net = conv2d(net, 64, 1, name=\"conv3_2\")\n",
        "    net = conv2d(net, 128, 3, 1, name=\"conv3_3\")\n",
        "    net = maxpool(net, name=\"pool3\")\n",
        "    net = conv2d(net, 256, 3, 1, name=\"conv4_1\")\n",
        "    net = conv2d(net, 128, 1, name=\"conv4_2\")\n",
        "    net = conv2d(net, 256, 3, 1, name=\"conv4_3\")\n",
        "    net = maxpool(net, name=\"pool4\")\n",
        "    net = conv2d(net, 512, 3, 1, name=\"conv5_1\")\n",
        "    net = conv2d(net, 256, 1, name=\"conv5_2\")\n",
        "    net = conv2d(net, 512, 3, 1, name=\"conv5_3\")\n",
        "    net = conv2d(net, 256, 1, name=\"conv5_4\")\n",
        "    net = conv2d(net, 512, 3, 1, name=\"conv5_5\")\n",
        "    shortcut = net\n",
        "    net = maxpool(net, name=\"pool5\")\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv6_1\")\n",
        "    net = conv2d(net, 512, 1, name=\"conv6_2\")\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv6_3\")\n",
        "    net = conv2d(net, 512, 1, name=\"conv6_4\")\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv6_5\")\n",
        "    # ---------\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv7_1\")\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv7_2\")\n",
        "    # shortcut\n",
        "    shortcut = conv2d(shortcut, 64, 1, name=\"conv_shortcut\")\n",
        "    shortcut = reorg(shortcut, 2)\n",
        "    net = tf.concat([shortcut, net], axis=-1)\n",
        "    net = conv2d(net, 1024, 3, 1, name=\"conv8\")\n",
        "    # detection layer\n",
        "    net = conv2d(net, n_last_channels, 1, batch_normalize=0,\n",
        "                 activation=None, use_bias=True, name=\"conv_dec\")\n",
        "    return net\n",
        "\n",
        "\n",
        "#test\n",
        "if __name__ == \"__main__\":\n",
        "    x = tf.random.normal([1, 416, 416, 3])\n",
        "    model = darknet(x)\n",
        "    print(model)\n"
      ],
      "metadata": {
        "id": "YmEvR-PuRjNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bottleneck_semantic_segmentation (U-Net)"
      ],
      "metadata": {
        "id": "NLfYocU7yEUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs):\n",
        "    probe_number = 200\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "            print(\"LR\", param_group['lr'])\n",
        "            model.train()\n",
        "\n",
        "        inner_epoch_count = 0\n",
        "        running_loss = 0\n",
        "\n",
        "        for inputs, labels in tqdm(Train_Dataloader):\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            #epoch_samples += inputs.size(0)\n",
        "            running_loss = running_loss + loss.item()\n",
        "            inner_epoch_count = inner_epoch_count + 1\n",
        "            if inner_epoch_count % probe_number == probe_number - 1:\n",
        "                # Plot predict mask\n",
        "                pred_np = outputs.data.cpu().numpy()[0]\n",
        "                pred_argmax = np.argmax(pred_np, axis = 0)\n",
        "                print(f\"Prediction {np.unique(pred_argmax)}\")\n",
        "                plt.imshow(pred_argmax/10)\n",
        "                plt.show()\n",
        "\n",
        "                # Plot ground truth mask\n",
        "                lab_np = labels.data.cpu().numpy()[0]\n",
        "                print(f\"Answer: {np.unique(lab_np)}\")\n",
        "                plt.imshow(lab_np/10)\n",
        "                plt.show()\n",
        "\n",
        "                # Plot input image\n",
        "                inp_np = inputs.data.cpu().numpy()[0].transpose((1, 2, 0))\n",
        "                plt.imshow(inp_np)\n",
        "                plt.show()\n",
        "                print(\"============================\")\n",
        "                print(f\"[Epoch {epoch}/{num_epochs - 1}] Running loss: {round(running_loss / probe_number, 3)}\")\n",
        "                loss_list.append(running_loss / probe_number)\n",
        "                running_loss = 0\n",
        "                print(\"============================\")\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return model, loss_list"
      ],
      "metadata": {
        "id": "a3uv0dWwrB79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "\n",
        "        x = self.dconv_down4(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.dconv_up1(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "oLN1OqScjGIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "num_class = 10\n",
        "num_epochs = 150\n",
        "\n",
        "model = UNet(num_class).to(device)\n",
        "\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr = 1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 25, gamma = 0.1)\n",
        "\n",
        "model, loss_list = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs = num_epochs)\n"
      ],
      "metadata": {
        "id": "7DQK3Ovzi0dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x4-xDmn5wYKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}